{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import bs4\n",
    "import urllib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2000.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 100\n",
    "mlatCutOffUpper = 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ Dst and AE data\n",
    "inpDstFile = \"../data/dst_out_file.csv\"\n",
    "dstDF = pandas.read_csv(inpDstFile, sep=' ',\\\n",
    "                infer_datetime_format=True,\\\n",
    "                        parse_dates=[\"dst_date\"])\n",
    "dstDF = dstDF[ (dstDF[\"dst_date\"] > datetime.datetime(2010,12,31)) &\\\n",
    "             (dstDF[\"dst_date\"] < datetime.datetime(2015,1,1))].reset_index(drop=True)\n",
    "dstDF = dstDF[ dstDF[\"dst_index\"] <= 10. ].reset_index(drop=True)\n",
    "dstDF[\"dtStr\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%H'))\n",
    "# Aur Inds\n",
    "aurDF = pandas.read_csv( \"../data/aur_processed.txt\", sep=' ' )\n",
    "aurDF[\"date\"] = pandas.to_datetime(aurDF[\"datetimeStr\"], format='%Y%m%d-%H-%M')\n",
    "aurDF[\"hour\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "aurDF[\"minute\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "aurDF[\"dtStr\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "# a helper function to convert seperate date\n",
    "# and time strings to datetime objects  \n",
    "fitVelFile = \"../data/fitres.csv\"\n",
    "inpColNames = [\"azim\", \"azimStd\", \"delMLT\", \"endPtMLAT\",\\\n",
    "               \"endPtNormMLT\",\"goodFit\", \"MLAT\", \"normMLT\",\\\n",
    "               \"vSaps\", \"velSTD\", \"date\"]\n",
    "# velsDataDF = pandas.read_csv(fitVelFile, sep=' ', header=None)\n",
    "# velsDataDF.columns = inpColNames\n",
    "velsDataDF = pandas.read_csv(fitVelFile, sep=' ',\\\n",
    "                             header=None, names=inpColNames,\\\n",
    "                            infer_datetime_format=True,\\\n",
    "                            parse_dates=[\"date\"])\n",
    "velsDataDF.head()\n",
    "velsDataDF[\"dtStr\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velsDataDF = velsDataDF[ (velsDataDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velsDataDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velsDataDF = velsDataDF[ velsDataDF[\"MLAT\"] < mlatCutOffUpper ].reset_index(drop=True)\n",
    "velsDataDF[\"hour\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "velsDataDF[\"minute\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "# Now merge the dst and velocity DFs\n",
    "velsDataDF = pandas.merge( velsDataDF, dstDF,\\\n",
    "                          on=[\"dtStr\", \"hour\"], how='inner' )\n",
    "# We generally work with Dst bins, set them up\n",
    "# add dst_bins\n",
    "dstBins = [ -150, -75, -50, -25, -10, 10 ]\n",
    "velsDataDF = pandas.concat( [ velsDataDF, \\\n",
    "                    pandas.cut( velsDataDF[\"dst_index\"], \\\n",
    "                               bins=dstBins ) ], axis=1 )\n",
    "velsDataDF.columns = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "                      'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date',\\\n",
    "                      'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin']\n",
    "# Also merge with aurDF\n",
    "# print \"pre merge shape-->\", velsDataDF.shape\n",
    "velsDataDF = pandas.merge( velsDataDF, aurDF,\\\n",
    "                         on=[\"dtStr\", \"hour\", \"minute\"], how='inner')\n",
    "# Discard some unwanted cols\n",
    "selColsVels = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "               'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date_x',\\\n",
    "               'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin',\\\n",
    "               'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "velsDataDF = velsDataDF[ selColsVels ]\n",
    "velsDataDF.columns = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "               'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date',\\\n",
    "               'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin',\\\n",
    "               'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "# velsDataDF.head()\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT', 'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date', 'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin', 'datetimeStr', 'AE', 'AL', 'AO', 'AU', 'count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azim</th>\n",
       "      <th>azimStd</th>\n",
       "      <th>delMLT</th>\n",
       "      <th>endPtMLAT</th>\n",
       "      <th>endPtNormMLT</th>\n",
       "      <th>goodFit</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>normMLT</th>\n",
       "      <th>vSaps</th>\n",
       "      <th>velSTD</th>\n",
       "      <th>...</th>\n",
       "      <th>minute</th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>datetimeStr</th>\n",
       "      <th>AE</th>\n",
       "      <th>AL</th>\n",
       "      <th>AO</th>\n",
       "      <th>AU</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.387108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>False</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>902.535876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>2012-10-23 07:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>20121023-07-24</td>\n",
       "      <td>121</td>\n",
       "      <td>-98</td>\n",
       "      <td>-38</td>\n",
       "      <td>23</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.516834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.04</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>False</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>659.606637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2012-10-23 07:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>20121023-07-26</td>\n",
       "      <td>116</td>\n",
       "      <td>-100</td>\n",
       "      <td>-42</td>\n",
       "      <td>16</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.533716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.12</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>False</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704.274601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>2012-10-23 07:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>20121023-07-28</td>\n",
       "      <td>106</td>\n",
       "      <td>-87</td>\n",
       "      <td>-34</td>\n",
       "      <td>19</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.011539</td>\n",
       "      <td>3.652241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.631334</td>\n",
       "      <td>57.540267</td>\n",
       "      <td>...</td>\n",
       "      <td>08</td>\n",
       "      <td>2011-09-20 06:00:00</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>(-25, -10]</td>\n",
       "      <td>20110920-06-08</td>\n",
       "      <td>110</td>\n",
       "      <td>-52</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.011539</td>\n",
       "      <td>3.652241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.631334</td>\n",
       "      <td>57.540267</td>\n",
       "      <td>...</td>\n",
       "      <td>08</td>\n",
       "      <td>2011-09-20 06:00:00</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>(-25, -10]</td>\n",
       "      <td>20110920-06-08</td>\n",
       "      <td>110</td>\n",
       "      <td>-52</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        azim   azimStd  delMLT  endPtMLAT  endPtNormMLT goodFit  MLAT  \\\n",
       "0  -3.387108       NaN     NaN      63.05         -0.90   False  63.0   \n",
       "1  -3.516834       NaN     NaN      63.04         -0.66   False  63.0   \n",
       "2  -9.533716       NaN     NaN      63.12         -0.69   False  63.0   \n",
       "3 -18.011539  3.652241     1.0        NaN           NaN    True  63.0   \n",
       "4 -18.011539  3.652241     1.0        NaN           NaN    True  63.0   \n",
       "\n",
       "   normMLT       vSaps     velSTD  ...   minute            dst_date dst_index  \\\n",
       "0      0.0  902.535876        NaN  ...       24 2012-10-23 07:00:00       4.0   \n",
       "1      0.0  659.606637        NaN  ...       26 2012-10-23 07:00:00       4.0   \n",
       "2      0.0  704.274601        NaN  ...       28 2012-10-23 07:00:00       4.0   \n",
       "3      0.0  441.631334  57.540267  ...       08 2011-09-20 06:00:00     -24.0   \n",
       "4      0.0  441.631334  57.540267  ...       08 2011-09-20 06:00:00     -24.0   \n",
       "\n",
       "      dst_bin     datetimeStr   AE   AL  AO  AU  count  \n",
       "0   (-10, 10]  20121023-07-24  121  -98 -38  23    284  \n",
       "1   (-10, 10]  20121023-07-26  116 -100 -42  16    284  \n",
       "2   (-10, 10]  20121023-07-28  106  -87 -34  19    284  \n",
       "3  (-25, -10]  20110920-06-08  110  -52   3  58    284  \n",
       "4  (-25, -10]  20110920-06-08  110  -52   3  58    284  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out some values where number of datapoints are pretty low.\n",
    "countDF = velsDataDF.groupby([ \"normMLT\", \"MLAT\" ]).size().reset_index()\n",
    "countDF.columns = [ \"normMLT\", \"MLAT\", \"count\" ]\n",
    "# Choose only columns which have atleast 100 points\n",
    "countDF = countDF[ countDF[\"count\"] >= numPointsCutoffMLTMLAT ].reset_index(drop=True)\n",
    "# Merge with velsDataDF to filter out unwanted values\n",
    "velsDataDF = pandas.merge( velsDataDF, countDF,\\\n",
    "                          on=[\"normMLT\", \"MLAT\"], how='inner' )\n",
    "velsDataDF.to_csv(\"../data/processed-vels-geomag.txt\", sep=' ', index=False)\n",
    "print velsDataDF.columns.tolist()\n",
    "velsDataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
