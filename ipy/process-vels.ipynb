{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import bs4\n",
    "import urllib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2500.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 25\n",
    "perCutoffMLTMLAT = 0.15\n",
    "mlatCutOffUpper = 65.\n",
    "mlatCutOffLower = 53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ Dst and AE data\n",
    "inpDstFile = \"../data/dst_out_file.csv\"\n",
    "dstDF = pandas.read_csv(inpDstFile, sep=' ',\\\n",
    "                infer_datetime_format=True,\\\n",
    "                        parse_dates=[\"dst_date\"])\n",
    "dstDF = dstDF[ (dstDF[\"dst_date\"] > datetime.datetime(2010,12,31)) &\\\n",
    "             (dstDF[\"dst_date\"] < datetime.datetime(2015,1,1))].reset_index(drop=True)\n",
    "dstDF = dstDF[ dstDF[\"dst_index\"] <= 10. ].reset_index(drop=True)\n",
    "dstDF[\"dtStr\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%H'))\n",
    "# Aur Inds\n",
    "aurDF = pandas.read_csv( \"../data/aur_processed.txt\", sep=' ' )\n",
    "aurDF[\"date\"] = pandas.to_datetime(aurDF[\"datetimeStr\"], format='%Y%m%d-%H-%M')\n",
    "aurDF[\"hour\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "aurDF[\"minute\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "aurDF[\"dtStr\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "# a helper function to convert seperate date\n",
    "# and time strings to datetime objects  \n",
    "fitVelFile = \"../data/fitres-fin.csv\"\n",
    "inpColNames = [\"azim\", \"azimStd\", \"delMLT\", \"endPtMLAT\",\\\n",
    "               \"endPtNormMLT\",\"goodFit\", \"MLAT\", \"normMLT\",\\\n",
    "               \"vSaps\", \"velSTD\", \"date\"]\n",
    "if ( (\"extra\" in fitVelFile) or (\"fin\" in fitVelFile) ):\n",
    "    inpColNames = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date\"]\n",
    "# velsDataDF = pandas.read_csv(fitVelFile, sep=' ', header=None)\n",
    "# velsDataDF.columns = inpColNames\n",
    "velsDataDF = pandas.read_csv(fitVelFile, sep=' ',\\\n",
    "                             header=None, names=inpColNames,\\\n",
    "                            infer_datetime_format=True,\\\n",
    "                            parse_dates=[\"date\"])\n",
    "\n",
    "velsDataDF[\"dtStr\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velsDataDF = velsDataDF[ (velsDataDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velsDataDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velsDataDF = velsDataDF[ (velsDataDF[\"MLAT\"] < mlatCutOffUpper) &\\\n",
    "                       (velsDataDF[\"MLAT\"] > mlatCutOffLower) ].reset_index(drop=True)\n",
    "velsDataDF[\"hour\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "velsDataDF[\"minute\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "# Now merge the dst and velocity DFs\n",
    "velsDataDF = pandas.merge( velsDataDF, dstDF,\\\n",
    "                          on=[\"dtStr\", \"hour\"], how='inner' )\n",
    "# We generally work with Dst bins, set them up\n",
    "# add dst_bins\n",
    "dstBins = [ -150, -75, -50, -25, -10, 10 ]\n",
    "velsDataDF = pandas.concat( [ velsDataDF, \\\n",
    "                    pandas.cut( velsDataDF[\"dst_index\"], \\\n",
    "                               bins=dstBins ) ], axis=1 )\n",
    "velsDataDF.columns = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "                      'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date',\\\n",
    "                      'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin']\n",
    "if ( (\"extra\" in fitVelFile) or (\"fin\" in fitVelFile) ):\n",
    "    velsDataDF.columns = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date\",\\\n",
    "                'dtStr', 'hour', 'minute', 'dst_date',\\\n",
    "                'dst_index', 'dst_bin']\n",
    "# Also merge with aurDF\n",
    "# print \"pre merge shape-->\", velsDataDF.shape\n",
    "velsDataDF = pandas.merge( velsDataDF, aurDF,\\\n",
    "                         on=[\"dtStr\", \"hour\", \"minute\"], how='inner')\n",
    "# Discard some unwanted cols\n",
    "selColsVels = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "               'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date_x',\\\n",
    "               'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin',\\\n",
    "               'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "if ( (\"extra\" in fitVelFile) or (\"fin\" in fitVelFile) ):\n",
    "    selColsVels = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date_x\",\\\n",
    "                'dtStr', 'hour', 'minute', 'dst_date',\\\n",
    "                'dst_index', 'dst_bin', 'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "velsDataDF = velsDataDF[ selColsVels ]\n",
    "velsDataDF.columns = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "               'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date',\\\n",
    "               'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin',\\\n",
    "               'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "if ( (\"extra\" in fitVelFile) or (\"fin\" in fitVelFile) ):\n",
    "    velsDataDF.columns = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date\",\\\n",
    "                'dtStr', 'hour', 'minute', 'dst_date',\\\n",
    "                'dst_index', 'dst_bin', 'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azim</th>\n",
       "      <th>azimStd</th>\n",
       "      <th>delMLT</th>\n",
       "      <th>goodFit</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>normMLT</th>\n",
       "      <th>vSaps</th>\n",
       "      <th>velSTD</th>\n",
       "      <th>endPtMLAT</th>\n",
       "      <th>endPtNormMLT</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>datetimeStr</th>\n",
       "      <th>AE</th>\n",
       "      <th>AL</th>\n",
       "      <th>AO</th>\n",
       "      <th>AU</th>\n",
       "      <th>count</th>\n",
       "      <th>maxCount</th>\n",
       "      <th>probOcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.587427</td>\n",
       "      <td>1.794202</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>306.738497</td>\n",
       "      <td>11.198685</td>\n",
       "      <td>62.06</td>\n",
       "      <td>-6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20121014-01-00</td>\n",
       "      <td>500</td>\n",
       "      <td>-343</td>\n",
       "      <td>-93</td>\n",
       "      <td>157</td>\n",
       "      <td>470</td>\n",
       "      <td>2562</td>\n",
       "      <td>0.18345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.524308</td>\n",
       "      <td>1.486233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>301.958739</td>\n",
       "      <td>8.617099</td>\n",
       "      <td>62.07</td>\n",
       "      <td>-6.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20121014-01-02</td>\n",
       "      <td>490</td>\n",
       "      <td>-341</td>\n",
       "      <td>-96</td>\n",
       "      <td>149</td>\n",
       "      <td>470</td>\n",
       "      <td>2562</td>\n",
       "      <td>0.18345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.704231</td>\n",
       "      <td>1.771100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>328.832509</td>\n",
       "      <td>13.365574</td>\n",
       "      <td>62.07</td>\n",
       "      <td>-6.32</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20121014-01-04</td>\n",
       "      <td>527</td>\n",
       "      <td>-371</td>\n",
       "      <td>-108</td>\n",
       "      <td>156</td>\n",
       "      <td>470</td>\n",
       "      <td>2562</td>\n",
       "      <td>0.18345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.402638</td>\n",
       "      <td>1.525368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>357.951508</td>\n",
       "      <td>12.264929</td>\n",
       "      <td>62.07</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20121014-01-06</td>\n",
       "      <td>515</td>\n",
       "      <td>-366</td>\n",
       "      <td>-109</td>\n",
       "      <td>149</td>\n",
       "      <td>470</td>\n",
       "      <td>2562</td>\n",
       "      <td>0.18345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.586116</td>\n",
       "      <td>1.070948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>406.549966</td>\n",
       "      <td>10.616775</td>\n",
       "      <td>62.08</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20121014-01-08</td>\n",
       "      <td>527</td>\n",
       "      <td>-373</td>\n",
       "      <td>-110</td>\n",
       "      <td>154</td>\n",
       "      <td>470</td>\n",
       "      <td>2562</td>\n",
       "      <td>0.18345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        azim   azimStd  delMLT goodFit  MLAT  normMLT       vSaps     velSTD  \\\n",
       "0 -10.587427  1.794202     0.5    True  62.0     -6.0  306.738497  11.198685   \n",
       "1 -13.524308  1.486233     1.0    True  62.0     -6.0  301.958739   8.617099   \n",
       "2 -11.704231  1.771100     0.5    True  62.0     -6.0  328.832509  13.365574   \n",
       "3 -11.402638  1.525368     1.0    True  62.0     -6.0  357.951508  12.264929   \n",
       "4 -11.586116  1.070948     1.0    True  62.0     -6.0  406.549966  10.616775   \n",
       "\n",
       "   endPtMLAT  endPtNormMLT   ...    dst_index     dst_bin     datetimeStr  \\\n",
       "0      62.06         -6.30   ...        -44.0  (-50, -25]  20121014-01-00   \n",
       "1      62.07         -6.29   ...        -44.0  (-50, -25]  20121014-01-02   \n",
       "2      62.07         -6.32   ...        -44.0  (-50, -25]  20121014-01-04   \n",
       "3      62.07         -6.35   ...        -44.0  (-50, -25]  20121014-01-06   \n",
       "4      62.08         -6.40   ...        -44.0  (-50, -25]  20121014-01-08   \n",
       "\n",
       "    AE   AL   AO   AU count  maxCount  probOcc  \n",
       "0  500 -343  -93  157   470      2562  0.18345  \n",
       "1  490 -341  -96  149   470      2562  0.18345  \n",
       "2  527 -371 -108  156   470      2562  0.18345  \n",
       "3  515 -366 -109  149   470      2562  0.18345  \n",
       "4  527 -373 -110  154   470      2562  0.18345  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out some values where number of percent datapoints are pretty low.\n",
    "# We'll not use a number but divide data into different Dst groups and\n",
    "# discard locations where number of points are relatively low.\n",
    "# Get max points at a given Lat, MLT, DstBin\n",
    "################## NEW METHOD ##################\n",
    "################## NEW METHOD ##################\n",
    "################## NEW METHOD ##################\n",
    "dstSapsMLTLatCountDF = velsDataDF.groupby([\"dst_bin\", \"normMLT\", \"MLAT\"]).size().reset_index()\n",
    "maxCntMLTLatDst = dstSapsMLTLatCountDF.groupby([\"dst_bin\"]).max().reset_index()\n",
    "maxCntMLTLatDst = maxCntMLTLatDst.drop([\"normMLT\", \"MLAT\"], 1)\n",
    "maxCntMLTLatDst.columns = [\"dst_bin\", \"maxCount\"]\n",
    "dstSapsMLTLatCountDF = pandas.merge( dstSapsMLTLatCountDF, maxCntMLTLatDst, \\\n",
    "                              on=[\"dst_bin\"], how='inner')\n",
    "dstSapsMLTLatCountDF.columns = [\"dst_bin\", \"normMLT\", \"MLAT\", \"count\", \"maxCount\"]\n",
    "dstSapsMLTLatCountDF[\"probOcc\"] = dstSapsMLTLatCountDF[\"count\"]/dstSapsMLTLatCountDF[\"maxCount\"]\n",
    "# Filter out unwanted values\n",
    "dstSapsMLTLatCountDF = dstSapsMLTLatCountDF[ \\\n",
    "                        dstSapsMLTLatCountDF[\"probOcc\"] >= perCutoffMLTMLAT\\\n",
    "                        ].reset_index(drop=True)\n",
    "velsDataDF = pandas.merge( velsDataDF, dstSapsMLTLatCountDF,\\\n",
    "                          on=[\"dst_bin\", \"normMLT\", \"MLAT\"], how='inner' )\n",
    "velsDataDF.to_csv(\"../data/processed-vels-geomag-fin.txt\", sep=' ', index=False)\n",
    "################## NEW METHOD ##################\n",
    "################## NEW METHOD ##################\n",
    "################## NEW METHOD ##################\n",
    "\n",
    "################## OLD METHOD ##################\n",
    "################## OLD METHOD ##################\n",
    "################## OLD METHOD ##################\n",
    "# countDF = velsDataDF.groupby([ \"normMLT\", \"MLAT\" ]).size().reset_index()\n",
    "# countDF.columns = [ \"normMLT\", \"MLAT\", \"count\" ]\n",
    "# # Choose only columns which have atleast 100 points\n",
    "# countDF = countDF[ countDF[\"count\"] >= numPointsCutoffMLTMLAT ].reset_index(drop=True)\n",
    "# # Merge with velsDataDF to filter out unwanted values\n",
    "# velsDataDF = pandas.merge( velsDataDF, countDF,\\\n",
    "#                           on=[\"normMLT\", \"MLAT\"], how='inner' )\n",
    "# velsDataDF.to_csv(\"../data/processed-vels-geomag-extra.txt\", sep=' ', index=False)\n",
    "# print velsDataDF.columns.tolist()\n",
    "################## OLD METHOD ##################\n",
    "################## OLD METHOD ##################\n",
    "################## OLD METHOD ##################\n",
    "velsDataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetimeStr\n",
      "20130629-02-50    32\n",
      "20130629-02-48    28\n",
      "20110913-03-54    24\n",
      "20110913-03-52    24\n",
      "20130629-02-52    20\n",
      "20110910-02-44    18\n",
      "20110910-02-50    18\n",
      "20110910-02-48    18\n",
      "20110910-02-46    18\n",
      "20110913-03-58    18\n",
      "20130607-04-56    16\n",
      "20130607-03-50    16\n",
      "20130629-02-56    16\n",
      "20130426-05-32    16\n",
      "20110913-04-00    15\n",
      "20110913-03-56    15\n",
      "20110910-02-30    15\n",
      "20130629-04-08    14\n",
      "20130629-04-06    14\n",
      "20130601-07-14    14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "velDatesDF = velsDataDF[ velsDataDF[\"vSaps\"] > 1500. ].groupby(\"datetimeStr\").size()\n",
    "print velDatesDF.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date        vSaps  delMLT      azim  MLAT  normMLT\n",
      "291295 2013-06-29 04:08:00  1260.381498     1.0 -5.467792  57.5     -5.0\n",
      "291296 2013-06-29 04:08:00  1260.381498     1.0 -5.467792  57.5     -5.0\n",
      "294841 2013-06-29 04:08:00  1522.122583     1.5 -8.116383  57.0     -5.0\n",
      "294842 2013-06-29 04:08:00  1522.122583     1.5 -8.116383  57.0     -5.0\n",
      "295697 2013-06-29 04:08:00  1564.357486     1.5 -4.973413  56.5     -5.0\n",
      "295698 2013-06-29 04:08:00  1564.357486     1.5 -4.973413  56.5     -5.0\n",
      "297707 2013-06-29 04:08:00  1608.601269     0.5 -1.595045  56.0     -5.0\n",
      "297708 2013-06-29 04:08:00  1608.601269     0.5 -1.595045  56.0     -5.0\n",
      "298325 2013-06-29 04:08:00  1381.663509     1.0 -3.752196  56.0     -4.0\n",
      "298326 2013-06-29 04:08:00  1381.663509     1.0 -3.752196  56.0     -4.0\n",
      "299394 2013-06-29 04:08:00  1564.357486     1.5 -4.973413  56.5     -4.0\n",
      "299395 2013-06-29 04:08:00  1564.357486     1.5 -4.973413  56.5     -4.0\n",
      "300103 2013-06-29 04:08:00  1506.884876     1.0 -9.195557  57.0     -4.0\n",
      "300104 2013-06-29 04:08:00  1506.884876     1.0 -9.195557  57.0     -4.0\n",
      "301301 2013-06-29 04:08:00  1407.423008     0.5 -0.301827  55.5     -5.0\n",
      "301302 2013-06-29 04:08:00  1407.423008     0.5 -0.301827  55.5     -5.0\n",
      "303519 2013-06-29 04:08:00  1377.854444     NaN -8.410904  54.5     -2.0\n",
      "303520 2013-06-29 04:08:00  1377.854444     NaN -8.410904  54.5     -2.0\n",
      "310930 2013-06-29 04:08:00  1625.415243     NaN -8.410904  55.5     -2.0\n",
      "310931 2013-06-29 04:08:00  1625.415243     NaN -8.410904  55.5     -2.0\n",
      "311129 2013-06-29 04:08:00  1727.887467     NaN -8.410904  55.0     -2.0\n",
      "311130 2013-06-29 04:08:00  1727.887467     NaN -8.410904  55.0     -2.0\n"
     ]
    }
   ],
   "source": [
    "print velsDataDF[ (velsDataDF[\"datetimeStr\"] == \"20130629-04-08\") &\\\n",
    "                (velsDataDF[\"vSaps\"] > 1200.) ][ [\"date\", \"vSaps\", \"delMLT\", \"azim\", \"MLAT\", \"normMLT\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
