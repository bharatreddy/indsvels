{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import bs4\n",
    "import urllib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2000.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 25\n",
    "mlatCutOffUpper = 65.\n",
    "mlatCutOffLower = 53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ Dst and AE data\n",
    "inpDstFile = \"../data/dst_out_file.csv\"\n",
    "dstDF = pandas.read_csv(inpDstFile, sep=' ',\\\n",
    "                infer_datetime_format=True,\\\n",
    "                        parse_dates=[\"dst_date\"])\n",
    "dstDF = dstDF[ (dstDF[\"dst_date\"] > datetime.datetime(2010,12,31)) &\\\n",
    "             (dstDF[\"dst_date\"] < datetime.datetime(2015,1,1))].reset_index(drop=True)\n",
    "dstDF = dstDF[ dstDF[\"dst_index\"] <= 10. ].reset_index(drop=True)\n",
    "dstDF[\"dtStr\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%H'))\n",
    "# Aur Inds\n",
    "aurDF = pandas.read_csv( \"../data/aur_processed.txt\", sep=' ' )\n",
    "aurDF[\"date\"] = pandas.to_datetime(aurDF[\"datetimeStr\"], format='%Y%m%d-%H-%M')\n",
    "aurDF[\"hour\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "aurDF[\"minute\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "aurDF[\"dtStr\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "# a helper function to convert seperate date\n",
    "# and time strings to datetime objects  \n",
    "fitVelFile = \"../data/fitres-extra.csv\"\n",
    "inpColNames = [\"azim\", \"azimStd\", \"delMLT\", \"endPtMLAT\",\\\n",
    "               \"endPtNormMLT\",\"goodFit\", \"MLAT\", \"normMLT\",\\\n",
    "               \"vSaps\", \"velSTD\", \"date\"]\n",
    "if \"extra\" in fitVelFile:\n",
    "    inpColNames = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date\"]\n",
    "# velsDataDF = pandas.read_csv(fitVelFile, sep=' ', header=None)\n",
    "# velsDataDF.columns = inpColNames\n",
    "velsDataDF = pandas.read_csv(fitVelFile, sep=' ',\\\n",
    "                             header=None, names=inpColNames,\\\n",
    "                            infer_datetime_format=True,\\\n",
    "                            parse_dates=[\"date\"])\n",
    "\n",
    "velsDataDF[\"dtStr\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velsDataDF = velsDataDF[ (velsDataDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velsDataDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velsDataDF = velsDataDF[ (velsDataDF[\"MLAT\"] < mlatCutOffUpper) &\\\n",
    "                       (velsDataDF[\"MLAT\"] > mlatCutOffLower) ].reset_index(drop=True)\n",
    "velsDataDF[\"hour\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "velsDataDF[\"minute\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "# Now merge the dst and velocity DFs\n",
    "velsDataDF = pandas.merge( velsDataDF, dstDF,\\\n",
    "                          on=[\"dtStr\", \"hour\"], how='inner' )\n",
    "# We generally work with Dst bins, set them up\n",
    "# add dst_bins\n",
    "dstBins = [ -150, -75, -50, -25, -10, 10 ]\n",
    "velsDataDF = pandas.concat( [ velsDataDF, \\\n",
    "                    pandas.cut( velsDataDF[\"dst_index\"], \\\n",
    "                               bins=dstBins ) ], axis=1 )\n",
    "velsDataDF.columns = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "                      'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date',\\\n",
    "                      'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin']\n",
    "if \"extra\" in fitVelFile:\n",
    "    velsDataDF.columns = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date\",\\\n",
    "                'dtStr', 'hour', 'minute', 'dst_date',\\\n",
    "                'dst_index', 'dst_bin']\n",
    "# Also merge with aurDF\n",
    "# print \"pre merge shape-->\", velsDataDF.shape\n",
    "velsDataDF = pandas.merge( velsDataDF, aurDF,\\\n",
    "                         on=[\"dtStr\", \"hour\", \"minute\"], how='inner')\n",
    "# Discard some unwanted cols\n",
    "selColsVels = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "               'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date_x',\\\n",
    "               'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin',\\\n",
    "               'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "if \"extra\" in fitVelFile:\n",
    "    selColsVels = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date_x\",\\\n",
    "                'dtStr', 'hour', 'minute', 'dst_date',\\\n",
    "                'dst_index', 'dst_bin', 'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "velsDataDF = velsDataDF[ selColsVels ]\n",
    "velsDataDF.columns = ['azim', 'azimStd', 'delMLT', 'endPtMLAT', 'endPtNormMLT',\\\n",
    "               'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'date',\\\n",
    "               'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin',\\\n",
    "               'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "if \"extra\" in fitVelFile:\n",
    "    velsDataDF.columns = [\"azim\", \"azimStd\", \"delMLT\", \"goodFit\",\\\n",
    "               \"MLAT\", \"normMLT\", \"vSaps\", \"velSTD\",\\\n",
    "               \"endPtMLAT\", \"endPtNormMLT\", \"date\",\\\n",
    "                'dtStr', 'hour', 'minute', 'dst_date',\\\n",
    "                'dst_index', 'dst_bin', 'datetimeStr', 'AE', 'AL', 'AO', 'AU']\n",
    "\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azim', 'azimStd', 'delMLT', 'goodFit', 'MLAT', 'normMLT', 'vSaps', 'velSTD', 'endPtMLAT', 'endPtNormMLT', 'date', 'dtStr', 'hour', 'minute', 'dst_date', 'dst_index', 'dst_bin', 'datetimeStr', 'AE', 'AL', 'AO', 'AU', 'count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azim</th>\n",
       "      <th>azimStd</th>\n",
       "      <th>delMLT</th>\n",
       "      <th>goodFit</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>normMLT</th>\n",
       "      <th>vSaps</th>\n",
       "      <th>velSTD</th>\n",
       "      <th>endPtMLAT</th>\n",
       "      <th>endPtNormMLT</th>\n",
       "      <th>...</th>\n",
       "      <th>minute</th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>datetimeStr</th>\n",
       "      <th>AE</th>\n",
       "      <th>AL</th>\n",
       "      <th>AO</th>\n",
       "      <th>AU</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.278027</td>\n",
       "      <td>3.056854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.581783</td>\n",
       "      <td>42.430720</td>\n",
       "      <td>56.51</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2013-10-02 08:00:00</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>(-75, -50]</td>\n",
       "      <td>20131002-08-26</td>\n",
       "      <td>552</td>\n",
       "      <td>-285</td>\n",
       "      <td>-9</td>\n",
       "      <td>267</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.278027</td>\n",
       "      <td>3.056854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.581783</td>\n",
       "      <td>42.430720</td>\n",
       "      <td>56.51</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2013-10-02 08:00:00</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>(-75, -50]</td>\n",
       "      <td>20131002-08-26</td>\n",
       "      <td>552</td>\n",
       "      <td>-285</td>\n",
       "      <td>-9</td>\n",
       "      <td>267</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.339227</td>\n",
       "      <td>3.271865</td>\n",
       "      <td>1.5</td>\n",
       "      <td>True</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373.463546</td>\n",
       "      <td>16.255793</td>\n",
       "      <td>56.48</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-02 05:00:00</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>(-25, -10]</td>\n",
       "      <td>20120702-05-36</td>\n",
       "      <td>596</td>\n",
       "      <td>-387</td>\n",
       "      <td>-89</td>\n",
       "      <td>209</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.392858</td>\n",
       "      <td>8.008279</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.444516</td>\n",
       "      <td>23.885030</td>\n",
       "      <td>56.38</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>04</td>\n",
       "      <td>2012-07-02 06:00:00</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20120702-06-04</td>\n",
       "      <td>839</td>\n",
       "      <td>-543</td>\n",
       "      <td>-124</td>\n",
       "      <td>296</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.945167</td>\n",
       "      <td>4.567263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.963263</td>\n",
       "      <td>26.111812</td>\n",
       "      <td>56.54</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2012-07-02 06:00:00</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(-50, -25]</td>\n",
       "      <td>20120702-06-20</td>\n",
       "      <td>833</td>\n",
       "      <td>-474</td>\n",
       "      <td>-58</td>\n",
       "      <td>359</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        azim   azimStd  delMLT goodFit  MLAT  normMLT       vSaps     velSTD  \\\n",
       "0  -1.278027  3.056854     1.0    True  56.5      0.0  439.581783  42.430720   \n",
       "1  -1.278027  3.056854     1.0    True  56.5      0.0  439.581783  42.430720   \n",
       "2   3.339227  3.271865     1.5    True  56.5      0.0  373.463546  16.255793   \n",
       "3  17.392858  8.008279     0.5    True  56.5      0.0  386.444516  23.885030   \n",
       "4  -5.945167  4.567263     1.0    True  56.5      0.0  379.963263  26.111812   \n",
       "\n",
       "   endPtMLAT  endPtNormMLT  ...   minute            dst_date dst_index  \\\n",
       "0      56.51         -0.44  ...       26 2013-10-02 08:00:00     -67.0   \n",
       "1      56.51         -0.44  ...       26 2013-10-02 08:00:00     -72.0   \n",
       "2      56.48         -0.37  ...       36 2012-07-02 05:00:00     -22.0   \n",
       "3      56.38         -0.37  ...       04 2012-07-02 06:00:00     -28.0   \n",
       "4      56.54         -0.38  ...       20 2012-07-02 06:00:00     -28.0   \n",
       "\n",
       "      dst_bin     datetimeStr   AE   AL   AO   AU  count  \n",
       "0  (-75, -50]  20131002-08-26  552 -285   -9  267    256  \n",
       "1  (-75, -50]  20131002-08-26  552 -285   -9  267    256  \n",
       "2  (-25, -10]  20120702-05-36  596 -387  -89  209    256  \n",
       "3  (-50, -25]  20120702-06-04  839 -543 -124  296    256  \n",
       "4  (-50, -25]  20120702-06-20  833 -474  -58  359    256  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out some values where number of percent datapoints are pretty low.\n",
    "# We'll not use a number but divide data into different Dst groups and\n",
    "# discard locations where number of points are relatively low.\n",
    "# For\n",
    "countDF = velsDataDF.groupby([ \"normMLT\", \"MLAT\" ]).size().reset_index()\n",
    "countDF.columns = [ \"normMLT\", \"MLAT\", \"count\" ]\n",
    "# Choose only columns which have atleast 100 points\n",
    "countDF = countDF[ countDF[\"count\"] >= numPointsCutoffMLTMLAT ].reset_index(drop=True)\n",
    "# Merge with velsDataDF to filter out unwanted values\n",
    "velsDataDF = pandas.merge( velsDataDF, countDF,\\\n",
    "                          on=[\"normMLT\", \"MLAT\"], how='inner' )\n",
    "velsDataDF.to_csv(\"../data/processed-vels-geomag-extra.txt\", sep=' ', index=False)\n",
    "print velsDataDF.columns.tolist()\n",
    "velsDataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
